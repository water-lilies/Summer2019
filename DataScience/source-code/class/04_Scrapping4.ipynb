{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lxml 사용 기초 스크랩핑\n",
    "\n",
    "- 네이버 메인의 신문사 url 갖고 옴 => xpath 사용\n",
    "- session을 사용하면 서버에서 일정 시간동안 연결된 정보를 사용할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml.html import fromstring, tostring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_news_list_page(response):\n",
    "    # URL 딕셔너리 선언\n",
    "    urls = {}\n",
    "    # 태그 정보 문자열 저장\n",
    "    root = fromstring(response.content)\n",
    "\n",
    "    # 문서내 경로 절대 경로 변환\n",
    "    root.make_links_absolute(response.url)\n",
    "    \n",
    "    # //*[@id=\"NS_032\"]\n",
    "    for a in root.xpath('//ul[@class=\"api_list\"]\n",
    "    /li[@class=\"api_item\"]/a[@class=\"api_link\"]'):\n",
    "    \n",
    "        # 신문사, 링크 추출 함수\n",
    "        name, url = extract_contents(a)\n",
    "\n",
    "        # 딕셔너리 삽입\n",
    "        urls[name] = url\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contents(dom):\n",
    "    # 링크 주소\n",
    "    link = dom.get('href')\n",
    "    \n",
    "    # 신문사 명 \n",
    "    # dom.xpath()는 리스트로 반환  //*[@id=\"NS_139\"]/a/img\n",
    "    name = dom.xpath('./img')[0].get('alt')\n",
    "    return name, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시사인 http://newsstand.naver.com/?list=ct1&pcode=308\n",
      "아이뉴스24 http://newsstand.naver.com/?list=ct1&pcode=031\n",
      "YTN http://newsstand.naver.com/?list=ct1&pcode=052\n",
      "중앙일보 http://newsstand.naver.com/?list=ct1&pcode=025\n",
      "한겨레 http://newsstand.naver.com/?list=ct1&pcode=028\n",
      "MBN http://newsstand.naver.com/?list=ct1&pcode=057\n",
      "프레시안 http://newsstand.naver.com/?list=ct1&pcode=002\n",
      "지지통신 http://newsstand.naver.com/?list=ct1&pcode=376\n",
      "스포츠조선 http://newsstand.naver.com/?list=ct1&pcode=076\n",
      "노컷뉴스 http://newsstand.naver.com/?list=ct1&pcode=079\n",
      "디지털타임스 http://newsstand.naver.com/?list=ct1&pcode=029\n",
      "아시아경제 http://newsstand.naver.com/?list=ct1&pcode=277\n",
      "연합인포맥스 http://newsstand.naver.com/?list=ct2&pcode=013\n",
      "건설경제신문 http://newsstand.naver.com/?list=ct2&pcode=960\n",
      "한국금융신문 http://newsstand.naver.com/?list=ct2&pcode=968\n",
      "코메디닷컴 http://newsstand.naver.com/?list=ct7&pcode=296\n",
      "디자인정글 http://newsstand.naver.com/?list=ct7&pcode=345\n",
      "엑스포츠뉴스 http://newsstand.naver.com/?list=ct6&pcode=311\n"
     ]
    }
   ],
   "source": [
    "# 세션 사용\n",
    "session = requests.Session()\n",
    "# 스크랩핑 대상 URL\n",
    "response = session.get('http://www.naver.com/')\n",
    "# 신문사 정보 딕셔너리 획득\n",
    "urls = scrape_news_list_page(response)\n",
    "# 딕셔너리 확인\n",
    "# print(urls)\n",
    "# 결과 출력\n",
    "for name, url in urls.items():\n",
    "    print(name, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
